{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ce432a3-080c-4633-8efe-1a78e5dc9c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read _results; Six types of execution multiplier chart+ TVR Fees analysis+ SARIMA\n",
    "import os, glob, math, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.stats.stattools import jarque_bera\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# basic settings\n",
    "RESULTS_DIR = \"./_results\"\n",
    "PANEL_PATH = os.path.join(RESULTS_DIR, \"panel_with_flags.csv\")\n",
    "COVER_PATH = os.path.join(RESULTS_DIR, \"category_coverage_report.csv\")\n",
    "OUTDIR = \"./_cat_results2\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "START = pd.Timestamp(\"2022-04-01\")\n",
    "END   = pd.Timestamp(\"2025-05-01\")\n",
    "SEASONAL_S = 7            \n",
    "MIN_LEN_FOR_MODEL = 100   # Modeling minimum effective sample points\n",
    "\n",
    "def _winsorize(s: pd.Series, p=0.01):\n",
    "    if s.isna().all():\n",
    "        return s\n",
    "    lo, hi = s.quantile(p), s.quantile(1-p)\n",
    "    return s.clip(lo, hi)\n",
    "\n",
    "def _safe_log(s: pd.Series):\n",
    "    return np.where(s > 0, np.log(s), np.nan)\n",
    "\n",
    "def choose_d_by_adf(y: pd.Series, max_d=2, alpha=0.05):\n",
    "    \"\"\"Select d step by step according to ADF differential selection (try to minimize d to make it stable)\"\"\"\n",
    "    d = 0\n",
    "    cur = y.dropna()\n",
    "    while d < max_d:\n",
    "        if len(cur) < 30:\n",
    "            break\n",
    "        pval = adfuller(cur, autolag=\"AIC\")[1]\n",
    "        if pval < alpha:\n",
    "            break  # Already stable\n",
    "        d += 1\n",
    "        cur = cur.diff().dropna()\n",
    "    return d\n",
    "\n",
    "def choose_D_weekly(y: pd.Series, alpha=0.05):\n",
    "    \"\"\"Select whether to perform weekly seasonal differencing (D=1)\"\"\"\n",
    "    if len(y.dropna()) < 30:\n",
    "        return 0\n",
    "    # Rough judgement: If y is more stable after its 7 lag differences, then take D=1.\n",
    "    p0 = adfuller(y.dropna(), autolag=\"AIC\")[1]\n",
    "    p1 = adfuller(y.diff(SEASONAL_S).dropna(), autolag=\"AIC\")[1]\n",
    "    return 1 if (p1 < alpha and (math.isnan(p0) or p0 >= alpha)) else 0\n",
    "\n",
    "def grid_search_sarima(y: pd.Series, d, D, s=SEASONAL_S,\n",
    "                       p_range=range(0,3), q_range=range(0,3),\n",
    "                       P_range=range(0,2), Q_range=range(0,2)):\n",
    "    \"\"\"Simple grid search, select the minimum AIC\"\"\"\n",
    "    best = {\"aic\": np.inf, \"order\": None, \"sorder\": None, \"model\": None}\n",
    "    for p in p_range:\n",
    "        for q in q_range:\n",
    "            for P in P_range:\n",
    "                for Q in Q_range:\n",
    "                    try:\n",
    "                        m = SARIMAX(y, order=(p,d,q), seasonal_order=(P,D,Q,s),\n",
    "                                    enforce_stationarity=False, enforce_invertibility=False)\n",
    "                        res = m.fit(disp=False)\n",
    "                        if res.aic < best[\"aic\"]:\n",
    "                            best = {\n",
    "                                \"aic\": res.aic, \"order\": (p,d,q),\n",
    "                                \"sorder\": (P,D,Q,s), \"model\": res\n",
    "                            }\n",
    "                    except Exception:\n",
    "                        continue\n",
    "    return best\n",
    "\n",
    "def save_fig(fig, path):\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(path, dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb83234f-6b2d-4ea5-973a-e42fc4582a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Categories of analysis： ['Liquid Staking', 'Lending', 'Yield', 'CDP', 'Dexs', 'Onchain Capital Allocator']\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "assert os.path.exists(PANEL_PATH), f\"cannot find {PANEL_PATH}\"\n",
    "assert os.path.exists(COVER_PATH), f\"cannot find {COVER_PATH}\"\n",
    "\n",
    "panel = pd.read_csv(PANEL_PATH, parse_dates=[\"date\"])\n",
    "panel[\"date\"] = panel[\"date\"].dt.tz_convert(\"UTC\").dt.tz_localize(None)  # Remove time zone\n",
    "cover = pd.read_csv(COVER_PATH)\n",
    "\n",
    "# Take the categories pass the ARIMA/SARIMA (ok_arima_tvr=True)\n",
    "pass_cats = cover.loc[cover[\"ok_arima_tvr\"], \"category\"].tolist()\n",
    "print(\"✓ Categories of analysis：\", pass_cats)\n",
    "\n",
    "# Retain only time window\n",
    "panel = panel[(panel[\"date\"] >= START) & (panel[\"date\"] <= END)].copy()\n",
    "panel = panel.sort_values([\"category\",\"date\"]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "EVENTS = [\n",
    "    # Interval events: Use shadows\n",
    "    {\"name\": \"LUNA Collapse\", \"start\": \"2022-05-09\", \"end\": \"2022-05-12\"},\n",
    "    {\"name\": \"FTX Collapse\",  \"start\": \"2022-11-08\", \"end\": \"2022-11-11\"},\n",
    "    # Single-day events: Use vertical lines\n",
    "    {\"name\": \"The Merge\",     \"date\":  \"2022-09-15\"},\n",
    "    {\"name\": \"Shapella\",      \"date\":  \"2023-04-12\"},  # ETH withdrawals available.\n",
    "]\n",
    "\n",
    "def add_events(ax, index_like):\n",
    "    y_top = ax.get_ylim()[1]\n",
    "    for ev in EVENTS:\n",
    "        if \"start\" in ev:\n",
    "            s = pd.to_datetime(ev[\"start\"]); e = pd.to_datetime(ev[\"end\"])\n",
    "            ax.axvspan(s, e, alpha=0.12)\n",
    "            ax.text(s, y_top, ev[\"name\"], rotation=90, va=\"top\", ha=\"left\", fontsize=9)\n",
    "        else:\n",
    "            d = pd.to_datetime(ev[\"date\"])\n",
    "            ax.axvline(d, linestyle=\"--\", linewidth=1)\n",
    "            ax.text(d, y_top, ev[\"name\"], rotation=90, va=\"top\", ha=\"center\", fontsize=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0539ec-9962-4213-b649-6cb027565ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def _winsorize(s, p=0.01):\n",
    "    s = pd.to_numeric(s, errors=\"coerce\")\n",
    "    lo, hi = s.quantile(p), s.quantile(1-p)\n",
    "    return s.clip(lo, hi)\n",
    "\n",
    "def _safe_log(s):\n",
    "    s = pd.to_numeric(s, errors=\"coerce\")\n",
    "    return np.where(s > 0, np.log(s), np.nan)\n",
    "\n",
    "cats = pass_cats if 'pass_cats' in globals() else (\n",
    "    cover.loc[cover.get('ok_arima_tvr', True), 'category'].tolist()\n",
    ")\n",
    "\n",
    "summary_rows = []        \n",
    "corr_rows = []      \n",
    "\n",
    "for cat in cats:\n",
    "    # 1. Retrieving data and indexing\n",
    "    g = panel.loc[panel[\"category\"] == cat].copy()\n",
    "    if g.empty:\n",
    "        continue\n",
    "    g = g.sort_values(\"date\").set_index(\"date\")\n",
    "\n",
    "    # 2. Multiplier stabilisation\n",
    "    if \"mult_daily\" in g.columns:\n",
    "        g[\"mult_daily_w\"] = _winsorize(g[\"mult_daily\"].astype(float), p=0.01)\n",
    "    else:\n",
    "        g[\"mult_daily_w\"] = np.nan\n",
    "\n",
    "    # 3.Fees stabilisation + logarithm \n",
    "    if \"Fees\" in g.columns:\n",
    "        g[\"Fees_w\"]   = _winsorize(g[\"Fees\"].astype(float), p=0.01)\n",
    "        g[\"log_Fees\"] = _safe_log(g[\"Fees_w\"])\n",
    "    else:\n",
    "        g[\"Fees_w\"] = np.nan\n",
    "        g[\"log_Fees\"] = np.nan\n",
    "\n",
    "    # 4.Modelling sequence\n",
    "    y_tvr = g[\"log_tvr_m\"].dropna() if \"log_tvr_m\" in g.columns else pd.Series(dtype=float)\n",
    "    y_tvl = g[\"log_tvl_m\"].dropna() if \"log_tvl_m\" in g.columns else pd.Series(dtype=float)\n",
    "\n",
    "    # picture 1：multiplier\n",
    "    \n",
    "    fig1 = plt.figure(figsize=(10,4))\n",
    "    ax1 = fig1.add_subplot(111)\n",
    "    ax1.plot(g.index, g[\"mult_daily_w\"])\n",
    "    ax1.set_title(f\"[{cat}] Daily Multiplier (winsorized 1%)\")\n",
    "    ax1.set_xlabel(\"date\"); ax1.set_ylabel(\"TVL / TVR\")\n",
    "    add_events(ax1, g.index)\n",
    "    save_fig(fig1, os.path.join(OUTDIR, f\"{cat}_multiplier_daily.png\"))\n",
    "\n",
    "    # 5. Correlation and regression\n",
    "    # TVR vs Fees\n",
    "    beta_tvr = np.nan; r_tvr = np.nan; rho_tvr = np.nan\n",
    "    df_corr_tvr = g[[\"log_tvr_m\", \"log_Fees\"]].dropna() if {\"log_tvr_m\",\"log_Fees\"}.issubset(g.columns) else pd.DataFrame()\n",
    "    if len(df_corr_tvr) >= 30:\n",
    "        X = df_corr_tvr[[\"log_tvr_m\"]].values\n",
    "        y_fee = df_corr_tvr[\"log_Fees\"].values\n",
    "        lr = LinearRegression().fit(X, y_fee)\n",
    "        beta_tvr = float(lr.coef_[0]); intercept_tvr = float(lr.intercept_)\n",
    "        r_tvr, p_tvr = pearsonr(df_corr_tvr[\"log_tvr_m\"].values, df_corr_tvr[\"log_Fees\"].values)\n",
    "        rho_tvr, p_rho_tvr = spearmanr(df_corr_tvr[\"log_tvr_m\"].values, df_corr_tvr[\"log_Fees\"].values)\n",
    "\n",
    "        # P2：Scatter plot + regression line\n",
    "        fig2 = plt.figure(figsize=(5,5))\n",
    "        ax2 = fig2.add_subplot(111)\n",
    "        ax2.scatter(df_corr_tvr[\"log_tvr_m\"], df_corr_tvr[\"log_Fees\"], s=8)\n",
    "        xline = np.linspace(df_corr_tvr[\"log_tvr_m\"].min(), df_corr_tvr[\"log_tvr_m\"].max(), 200)\n",
    "        yline = intercept_tvr + beta_tvr * xline\n",
    "        ax2.plot(xline, yline)\n",
    "        ax2.text(\n",
    "            0.02, 0.98,\n",
    "            f\"Pearson r={r_tvr:.3f} (p={p_tvr:.2g})\\n\"\n",
    "            f\"Spearman ρ={rho_tvr:.3f} (p={p_rho_tvr:.2g})\\n\"\n",
    "            f\"N={len(df_corr_tvr)}\",\n",
    "            transform=ax2.transAxes, va=\"top\", ha=\"left\",\n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", alpha=0.15)\n",
    "        )\n",
    "        ax2.set_title(f\"[{cat}] log(Fees) vs log(TVR)  β={beta_tvr:.3f}\")\n",
    "        ax2.set_xlabel(\"log(TVR)\"); ax2.set_ylabel(\"log(Fees)\")\n",
    "        save_fig(fig2, os.path.join(OUTDIR, f\"{cat}_corr_logFees_logTVR.png\"))\n",
    "    else:\n",
    "        p_tvr = p_rho_tvr = np.nan\n",
    "\n",
    "    # TVL vs Fees\n",
    "    beta_tvl = np.nan; r_tvl = np.nan; rho_tvl = np.nan\n",
    "    df_corr_tvl = g[[\"log_tvl_m\", \"log_Fees\"]].dropna() if {\"log_tvl_m\",\"log_Fees\"}.issubset(g.columns) else pd.DataFrame()\n",
    "    if len(df_corr_tvl) >= 30:\n",
    "        X2 = df_corr_tvl[[\"log_tvl_m\"]].values\n",
    "        y2 = df_corr_tvl[\"log_Fees\"].values\n",
    "        lr2 = LinearRegression().fit(X2, y2)\n",
    "        beta_tvl = float(lr2.coef_[0]); intercept_tvl = float(lr2.intercept_)\n",
    "        r_tvl, p_tvl = pearsonr(df_corr_tvl[\"log_tvl_m\"].values, df_corr_tvl[\"log_Fees\"].values)\n",
    "        rho_tvl, p_rho_tvl = spearmanr(df_corr_tvl[\"log_tvl_m\"].values, df_corr_tvl[\"log_Fees\"].values)\n",
    "\n",
    "        # P2b：\n",
    "        fig2b = plt.figure(figsize=(5,5))\n",
    "        ax2b = fig2b.add_subplot(111)\n",
    "        ax2b.scatter(df_corr_tvl[\"log_tvl_m\"], df_corr_tvl[\"log_Fees\"], s=8)\n",
    "        xline2 = np.linspace(df_corr_tvl[\"log_tvl_m\"].min(), df_corr_tvl[\"log_tvl_m\"].max(), 200)\n",
    "        yline2 = intercept_tvl + beta_tvl * xline2\n",
    "        ax2b.plot(xline2, yline2)\n",
    "        ax2b.text(\n",
    "            0.02, 0.98,\n",
    "            f\"Pearson r={r_tvl:.3f} (p={p_tvl:.2g})\\n\"\n",
    "            f\"Spearman ρ={rho_tvl:.3f} (p={p_rho_tvl:.2g})\\n\"\n",
    "            f\"N={len(df_corr_tvl)}\",\n",
    "            transform=ax2b.transAxes, va=\"top\", ha=\"left\",\n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", alpha=0.15)\n",
    "        )\n",
    "        ax2b.set_title(f\"[{cat}] log(Fees) vs log(TVL)  β={beta_tvl:.3f}\")\n",
    "        ax2b.set_xlabel(\"log(TVL)\"); ax2b.set_ylabel(\"log(Fees)\")\n",
    "        save_fig(fig2b, os.path.join(OUTDIR, f\"{cat}_corr_logFees_logTVL.png\"))\n",
    "    else:\n",
    "        p_tvl = p_rho_tvl = np.nan\n",
    "\n",
    "    #  6. SARIMA fitting\n",
    "    order = sorder = None; aic = np.nan\n",
    "    if len(y_tvr) >= MIN_LEN_FOR_MODEL:\n",
    "        d = choose_d_by_adf(y_tvr, max_d=2, alpha=0.05)\n",
    "        D = choose_D_weekly(y_tvr, alpha=0.05)\n",
    "        best = grid_search_sarima(y_tvr, d=d, D=D, s=SEASONAL_S)\n",
    "        if best[\"model\"] is not None:\n",
    "            res = best[\"model\"]; order = best[\"order\"]; sorder = best[\"sorder\"]; aic = float(res.aic)\n",
    "            try:\n",
    "                res = res.model.fit(start_params=res.params, cov_type='robust', disp=False)\n",
    "            except Exception:\n",
    "                try:\n",
    "                    res = res.model.fit(cov_type='robust', disp=False)\n",
    "                except Exception:\n",
    "                    pass\n",
    "            pred_in = res.get_prediction(start=y_tvr.index[0], end=y_tvr.index[-1], dynamic=False)\n",
    "            fit_log = pred_in.predicted_mean\n",
    "            burn = getattr(res, \"loglikelihood_burn\", 0)\n",
    "            if burn > 0:\n",
    "                fit_log = fit_log.iloc[burn:]; y_plot = y_tvr.iloc[burn:]\n",
    "            else:\n",
    "                y_plot = y_tvr\n",
    "            lo, hi = y_plot.quantile(0.001), y_plot.quantile(0.999)\n",
    "            fit_log = fit_log.clip(lo, hi)\n",
    "            fig3 = plt.figure(figsize=(10,4))\n",
    "            ax3 = fig3.add_subplot(111)\n",
    "            ax3.plot(y_plot.index, y_plot, label=\"log(TVR)\")\n",
    "            ax3.plot(fit_log.index, fit_log, label=\"Fitted log(TVR)\")\n",
    "            ax3.set_title(f\"[{cat}] TVR fit (in-sample)  order={order}, seasonal={sorder}, AIC={aic:.1f}\")\n",
    "            ax3.set_xlabel(\"date\"); ax3.set_ylabel(\"log USD\"); ax3.legend()\n",
    "            save_fig(fig3, os.path.join(OUTDIR, f\"{cat}_tvr_fit_log.png\"))\n",
    "\n",
    "    order_tvl = sorder_tvl = None; aic_tvl = np.nan\n",
    "    if len(y_tvl) >= MIN_LEN_FOR_MODEL:\n",
    "        d2 = choose_d_by_adf(y_tvl, max_d=2, alpha=0.05)\n",
    "        D2 = choose_D_weekly(y_tvl, alpha=0.05)\n",
    "        best2 = grid_search_sarima(y_tvl, d=d2, D=D2, s=SEASONAL_S)\n",
    "        if best2[\"model\"] is not None:\n",
    "            res2 = best2[\"model\"]; order_tvl = best2[\"order\"]; sorder_tvl = best2[\"sorder\"]; aic_tvl = float(res2.aic)\n",
    "            try:\n",
    "                res2 = res2.model.fit(start_params=res2.params, cov_type='robust', disp=False)\n",
    "            except Exception:\n",
    "                try:\n",
    "                    res2 = res2.model.fit(cov_type='robust', disp=False)\n",
    "                except Exception:\n",
    "                    pass\n",
    "            pred_in2 = res2.get_prediction(start=y_tvl.index[0], end=y_tvl.index[-1], dynamic=False)\n",
    "            fit_log2 = pred_in2.predicted_mean\n",
    "            burn2 = getattr(res2, \"loglikelihood_burn\", 0)\n",
    "            if burn2 > 0:\n",
    "                fit_log2 = fit_log2.iloc[burn2:]; y_plot2 = y_tvl.iloc[burn2:]\n",
    "            else:\n",
    "                y_plot2 = y_tvl\n",
    "            lo2, hi2 = y_plot2.quantile(0.001), y_plot2.quantile(0.999)\n",
    "            fit_log2 = fit_log2.clip(lo2, hi2)\n",
    "            fig3b = plt.figure(figsize=(10,4))\n",
    "            ax3b = fig3b.add_subplot(111)\n",
    "            ax3b.plot(y_plot2.index, y_plot2, label=\"log(TVL)\")\n",
    "            ax3b.plot(fit_log2.index, fit_log2, label=\"Fitted log(TVL)\")\n",
    "            ax3b.set_title(f\"[{cat}] TVL fit (in-sample)  order={order_tvl}, seasonal={sorder_tvl}, AIC={aic_tvl:.1f}\")\n",
    "            ax3b.set_xlabel(\"date\"); ax3b.set_ylabel(\"log USD\"); ax3b.legend()\n",
    "            save_fig(fig3b, os.path.join(OUTDIR, f\"{cat}_tvl_fit_log.png\"))\n",
    "\n",
    "    # 7. summary\n",
    "    cover_row = cover[cover[\"category\"]==cat].iloc[0].to_dict() if \"category\" in cover.columns and (cover[\"category\"]==cat).any() else {}\n",
    "    summary_rows.append(dict(\n",
    "        category=cat,\n",
    "        n_model_obs_TVR=len(y_tvr), order_TVR=str(order), seasonal_TVR=str(sorder), AIC_TVR=aic,\n",
    "        n_model_obs_TVL=len(y_tvl), order_TVL=str(order_tvl), seasonal_TVL=str(sorder_tvl), AIC_TVL=aic_tvl,\n",
    "        pearson_r_TVR=r_tvr, spearman_rho_TVR=rho_tvr,\n",
    "        pearson_r_TVL=r_tvl, spearman_rho_TVL=rho_tvl,\n",
    "        thr=float(cover_row.get(\"thr\", np.nan)),\n",
    "        tvr_coverage=float(cover_row.get(\"tvr_coverage\", np.nan)),\n",
    "        valid_coverage=float(cover_row.get(\"valid_coverage\", np.nan)),\n",
    "        N_tvr_pos=int(cover_row.get(\"N_tvr_pos\", 0)),\n",
    "        N_active=int(cover_row.get(\"N_active\", 0)),\n",
    "    ))\n",
    "\n",
    "    corr_rows.append(dict(\n",
    "        category=cat,\n",
    "        N_TVR=len(df_corr_tvr), pearson_r_TVR=r_tvr, pearson_p_TVR=(p_tvr if 'p_tvr' in locals() else np.nan),\n",
    "        spearman_rho_TVR=rho_tvr, spearman_p_TVR=(p_rho_tvr if 'p_rho_tvr' in locals() else np.nan),\n",
    "        N_TVL=len(df_corr_tvl), pearson_r_TVL=r_tvl, pearson_p_TVL=(p_tvl if 'p_tvl' in locals() else np.nan),\n",
    "        spearman_rho_TVL=rho_tvl, spearman_p_TVL=(p_rho_tvl if 'p_rho_tvl' in locals() else np.nan),\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f31edc3c-8a50-446a-8bac-bd2bda8dad36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved diagnostics to ./_cat_results2\\diagnostics\\sarima_residual_diagnostics.csv\n"
     ]
    }
   ],
   "source": [
    "# ====================== 追加：SARIMA 残差诊断（不改原循环） ======================\n",
    "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox, het_arch, normal_ad\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "\n",
    "# 可调参数\n",
    "DIAG_OUTDIR = os.path.join(OUTDIR, \"diagnostics\")\n",
    "os.makedirs(DIAG_OUTDIR, exist_ok=True)\n",
    "MAKE_PLOTS = True                 # 是否输出残差图（时序/ACF/PACF/Q-Q）\n",
    "LB_LAGS    = [14, 28]             # Ljung–Box 滞后\n",
    "ARCH_MAXLAG_FRACTION = 10         # ARCH-LM 的 maxlag ≈ len(resid)//这个数\n",
    "\n",
    "def _fit_and_diag_one(y: pd.Series, label: str, cat: str) -> dict:\n",
    "    \"\"\"\n",
    "    重新拟合该序列的 SARIMA（按你现有的规则），并返回残差诊断结果字典。\n",
    "    label: 'TVR' or 'TVL'\n",
    "    \"\"\"\n",
    "    out = {\n",
    "        \"category\": cat,\n",
    "        \"series\": label,\n",
    "        \"order\": None, \"seasonal\": None, \"AIC\": np.nan,\n",
    "        \"n_raw\": int(len(y)), \"n_eff\": np.nan,\n",
    "        \"lb_p14\": np.nan, \"lb_p28\": np.nan,\n",
    "        \"arch_p\": np.nan, \"norm_p\": np.nan,\n",
    "        \"stable\": np.nan, \"invertible\": np.nan,\n",
    "    }\n",
    "    if len(y) < MIN_LEN_FOR_MODEL:\n",
    "        return out\n",
    "\n",
    "    try:\n",
    "        d = choose_d_by_adf(y, max_d=2, alpha=0.05)\n",
    "        D = choose_D_weekly(y, alpha=0.05)\n",
    "        best = grid_search_sarima(y, d=d, D=D, s=SEASONAL_S)\n",
    "        if best.get(\"model\") is None:\n",
    "            return out\n",
    "        res = best[\"model\"]\n",
    "        order, sorder = best[\"order\"], best[\"sorder\"]\n",
    "        out[\"order\"], out[\"seasonal\"], out[\"AIC\"] = str(order), str(sorder), float(res.aic)\n",
    "\n",
    "        # 烧入期 & 残差\n",
    "        burn = int(getattr(res, \"loglikelihood_burn\", 0))\n",
    "        resid = res.resid\n",
    "        if hasattr(resid, \"iloc\") and burn > 0:\n",
    "            resid = resid.iloc[burn:]\n",
    "        resid = resid.dropna()\n",
    "        out[\"n_eff\"] = int(getattr(res, \"nobs\", len(y)) - burn)\n",
    "\n",
    "        # Ljung–Box（按可用 lags）\n",
    "        lags_use = [L for L in LB_LAGS if len(resid) > L]\n",
    "        if lags_use:\n",
    "            lb = acorr_ljungbox(resid, lags=lags_use, return_df=True)\n",
    "            try:\n",
    "                lb.index = lb.index.astype(int)\n",
    "            except Exception:\n",
    "                pass\n",
    "            out[\"lb_p14\"] = float(lb.loc[14, \"lb_pvalue\"]) if 14 in lb.index else np.nan\n",
    "            out[\"lb_p28\"] = float(lb.loc[28, \"lb_pvalue\"]) if 28 in lb.index else np.nan\n",
    "\n",
    "        # ARCH-LM（条件异方差）\n",
    "        arch_maxlag = max(1, min(12, len(resid)//ARCH_MAXLAG_FRACTION))\n",
    "        arch_stat, arch_p, _, _ = het_arch(resid, maxlag=arch_maxlag)\n",
    "        out[\"arch_p\"] = float(arch_p)\n",
    "\n",
    "        # 正态性（Anderson–Darling）\n",
    "        _, p_norm = normal_ad(resid)\n",
    "        out[\"norm_p\"] = float(p_norm)\n",
    "\n",
    "        # 稳定/可逆\n",
    "        ar_roots = getattr(res, \"arroots\", np.array([]))\n",
    "        ma_roots = getattr(res, \"maroots\", np.array([]))\n",
    "        out[\"stable\"]     = bool((np.abs(ar_roots) > 1).all()) if ar_roots.size else True\n",
    "        out[\"invertible\"] = bool((np.abs(ma_roots) > 1).all()) if ma_roots.size else True\n",
    "\n",
    "        # 可选：残差图\n",
    "        if MAKE_PLOTS:\n",
    "            # 残差时序\n",
    "            fig = plt.figure(figsize=(10,3.0)); ax = fig.add_subplot(111)\n",
    "            ax.plot(resid.index, resid.values, lw=0.8)\n",
    "            ax.axhline(0, ls='--', lw=0.8)\n",
    "            ax.set_title(f\"[{cat}] {label} residuals (burn-in removed)\")\n",
    "            ax.set_xlabel(\"date\"); ax.set_ylabel(\"residual\")\n",
    "            save_fig(fig, os.path.join(DIAG_OUTDIR, f\"{cat}_{label}_resid_ts.png\"))\n",
    "\n",
    "            # ACF\n",
    "            fig_acf = plt.figure(figsize=(5,3.0))\n",
    "            plot_acf(resid, lags=min(40, max(5, len(resid)//2)), alpha=0.05, ax=fig_acf.add_subplot(111))\n",
    "            fig_acf.suptitle(f\"[{cat}] {label} residual ACF\")\n",
    "            save_fig(fig_acf, os.path.join(DIAG_OUTDIR, f\"{cat}_{label}_resid_acf.png\"))\n",
    "\n",
    "            # PACF\n",
    "            fig_pacf = plt.figure(figsize=(5,3.0))\n",
    "            plot_pacf(resid, lags=min(40, max(5, len(resid)//2)), method=\"ywm\", alpha=0.05, ax=fig_pacf.add_subplot(111))\n",
    "            fig_pacf.suptitle(f\"[{cat}] {label} residual PACF\")\n",
    "            save_fig(fig_pacf, os.path.join(DIAG_OUTDIR, f\"{cat}_{label}_resid_pacf.png\"))\n",
    "\n",
    "            # Q–Q\n",
    "            fig_qq = plt.figure(figsize=(4.2,4.2))\n",
    "            qqplot(resid, line='s', ax=fig_qq.add_subplot(111))\n",
    "            fig_qq.suptitle(f\"[{cat}] {label} residual Q–Q\")\n",
    "            save_fig(fig_qq, os.path.join(DIAG_OUTDIR, f\"{cat}_{label}_resid_qq.png\"))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[{cat}] {label} diagnostics failed: {e}\")\n",
    "\n",
    "    return out\n",
    "\n",
    "# 逐类别运行诊断（重新拟合；不改原循环）\n",
    "diag_rows = []\n",
    "for cat in cats:\n",
    "    g = panel.loc[panel[\"category\"] == cat].copy()\n",
    "    if g.empty:\n",
    "        continue\n",
    "    g = g.sort_values(\"date\").set_index(\"date\")\n",
    "\n",
    "    y_tvr = g[\"log_tvr_m\"].dropna() if \"log_tvr_m\" in g.columns else pd.Series(dtype=float)\n",
    "    y_tvl = g[\"log_tvl_m\"].dropna() if \"log_tvl_m\" in g.columns else pd.Series(dtype=float)\n",
    "\n",
    "    # TVR\n",
    "    diag_rows.append(_fit_and_diag_one(y_tvr, \"TVR\", cat))\n",
    "    # TVL\n",
    "    diag_rows.append(_fit_and_diag_one(y_tvl, \"TVL\", cat))\n",
    "\n",
    "diag_df = pd.DataFrame(diag_rows)\n",
    "diag_csv_path = os.path.join(DIAG_OUTDIR, \"sarima_residual_diagnostics.csv\")\n",
    "diag_df.to_csv(diag_csv_path, index=False)\n",
    "print(\"✓ Saved diagnostics to\", diag_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf36fcd2-7aac-40da-bb70-cff928743382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ The correlation coefficient has been exported: ./_cat_results2\\correlation_summary.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>N_TVR</th>\n",
       "      <th>pearson_r_TVR</th>\n",
       "      <th>pearson_p_TVR</th>\n",
       "      <th>spearman_rho_TVR</th>\n",
       "      <th>spearman_p_TVR</th>\n",
       "      <th>N_TVL</th>\n",
       "      <th>pearson_r_TVL</th>\n",
       "      <th>pearson_p_TVL</th>\n",
       "      <th>spearman_rho_TVL</th>\n",
       "      <th>spearman_p_TVL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CDP</td>\n",
       "      <td>1123</td>\n",
       "      <td>-0.663549</td>\n",
       "      <td>1.925412e-143</td>\n",
       "      <td>-0.555057</td>\n",
       "      <td>9.557506e-92</td>\n",
       "      <td>1123</td>\n",
       "      <td>-0.415855</td>\n",
       "      <td>3.444147e-48</td>\n",
       "      <td>-0.344991</td>\n",
       "      <td>9.778137e-33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dexs</td>\n",
       "      <td>1123</td>\n",
       "      <td>0.246724</td>\n",
       "      <td>4.910709e-17</td>\n",
       "      <td>0.265541</td>\n",
       "      <td>1.408165e-19</td>\n",
       "      <td>1123</td>\n",
       "      <td>0.310997</td>\n",
       "      <td>1.316494e-26</td>\n",
       "      <td>0.282990</td>\n",
       "      <td>3.999583e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lending</td>\n",
       "      <td>652</td>\n",
       "      <td>0.799375</td>\n",
       "      <td>6.053668e-146</td>\n",
       "      <td>0.853784</td>\n",
       "      <td>2.022668e-186</td>\n",
       "      <td>652</td>\n",
       "      <td>0.889628</td>\n",
       "      <td>1.985401e-223</td>\n",
       "      <td>0.946290</td>\n",
       "      <td>6.007838e-321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Liquid Staking</td>\n",
       "      <td>1123</td>\n",
       "      <td>-0.292707</td>\n",
       "      <td>1.267058e-23</td>\n",
       "      <td>-0.368752</td>\n",
       "      <td>1.698197e-37</td>\n",
       "      <td>1123</td>\n",
       "      <td>0.938120</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.939493</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Onchain Capital Allocator</td>\n",
       "      <td>344</td>\n",
       "      <td>0.407119</td>\n",
       "      <td>3.637091e-15</td>\n",
       "      <td>0.308340</td>\n",
       "      <td>5.190069e-09</td>\n",
       "      <td>344</td>\n",
       "      <td>0.825363</td>\n",
       "      <td>6.506382e-87</td>\n",
       "      <td>0.820494</td>\n",
       "      <td>4.568177e-85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yield</td>\n",
       "      <td>1123</td>\n",
       "      <td>0.610175</td>\n",
       "      <td>1.681048e-115</td>\n",
       "      <td>0.587684</td>\n",
       "      <td>2.963637e-105</td>\n",
       "      <td>1123</td>\n",
       "      <td>0.391248</td>\n",
       "      <td>2.185565e-42</td>\n",
       "      <td>0.271688</td>\n",
       "      <td>1.872668e-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    category  N_TVR  pearson_r_TVR  pearson_p_TVR  \\\n",
       "3                        CDP   1123      -0.663549  1.925412e-143   \n",
       "4                       Dexs   1123       0.246724   4.910709e-17   \n",
       "1                    Lending    652       0.799375  6.053668e-146   \n",
       "0             Liquid Staking   1123      -0.292707   1.267058e-23   \n",
       "5  Onchain Capital Allocator    344       0.407119   3.637091e-15   \n",
       "2                      Yield   1123       0.610175  1.681048e-115   \n",
       "\n",
       "   spearman_rho_TVR  spearman_p_TVR  N_TVL  pearson_r_TVL  pearson_p_TVL  \\\n",
       "3         -0.555057    9.557506e-92   1123      -0.415855   3.444147e-48   \n",
       "4          0.265541    1.408165e-19   1123       0.310997   1.316494e-26   \n",
       "1          0.853784   2.022668e-186    652       0.889628  1.985401e-223   \n",
       "0         -0.368752    1.698197e-37   1123       0.938120   0.000000e+00   \n",
       "5          0.308340    5.190069e-09    344       0.825363   6.506382e-87   \n",
       "2          0.587684   2.963637e-105   1123       0.391248   2.185565e-42   \n",
       "\n",
       "   spearman_rho_TVL  spearman_p_TVL  \n",
       "3         -0.344991    9.778137e-33  \n",
       "4          0.282990    3.999583e-22  \n",
       "1          0.946290   6.007838e-321  \n",
       "0          0.939493    0.000000e+00  \n",
       "5          0.820494    4.568177e-85  \n",
       "2          0.271688    1.872668e-20  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ The model & correlation summary has been exported: ./_cat_results2\\model_and_corr_summary.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>n_model_obs_TVR</th>\n",
       "      <th>order_TVR</th>\n",
       "      <th>seasonal_TVR</th>\n",
       "      <th>AIC_TVR</th>\n",
       "      <th>n_model_obs_TVL</th>\n",
       "      <th>order_TVL</th>\n",
       "      <th>seasonal_TVL</th>\n",
       "      <th>AIC_TVL</th>\n",
       "      <th>pearson_r_TVR</th>\n",
       "      <th>spearman_rho_TVR</th>\n",
       "      <th>pearson_r_TVL</th>\n",
       "      <th>spearman_rho_TVL</th>\n",
       "      <th>thr</th>\n",
       "      <th>tvr_coverage</th>\n",
       "      <th>valid_coverage</th>\n",
       "      <th>N_tvr_pos</th>\n",
       "      <th>N_active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CDP</td>\n",
       "      <td>1123</td>\n",
       "      <td>(2, 1, 1)</td>\n",
       "      <td>(0, 1, 1, 7)</td>\n",
       "      <td>-2438.011021</td>\n",
       "      <td>1123</td>\n",
       "      <td>(1, 0, 0)</td>\n",
       "      <td>(0, 0, 0, 7)</td>\n",
       "      <td>-4838.770458</td>\n",
       "      <td>-0.663549</td>\n",
       "      <td>-0.555057</td>\n",
       "      <td>-0.415855</td>\n",
       "      <td>-0.344991</td>\n",
       "      <td>9.365115e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1127</td>\n",
       "      <td>1123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dexs</td>\n",
       "      <td>1123</td>\n",
       "      <td>(2, 1, 1)</td>\n",
       "      <td>(0, 1, 1, 7)</td>\n",
       "      <td>-2940.209362</td>\n",
       "      <td>1123</td>\n",
       "      <td>(2, 0, 1)</td>\n",
       "      <td>(0, 0, 0, 7)</td>\n",
       "      <td>-2486.573752</td>\n",
       "      <td>0.246724</td>\n",
       "      <td>0.265541</td>\n",
       "      <td>0.310997</td>\n",
       "      <td>0.282990</td>\n",
       "      <td>2.242641e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1127</td>\n",
       "      <td>1123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lending</td>\n",
       "      <td>1079</td>\n",
       "      <td>(1, 1, 2)</td>\n",
       "      <td>(1, 1, 1, 7)</td>\n",
       "      <td>-2891.671399</td>\n",
       "      <td>1079</td>\n",
       "      <td>(1, 1, 1)</td>\n",
       "      <td>(1, 1, 1, 7)</td>\n",
       "      <td>-1394.945813</td>\n",
       "      <td>0.799375</td>\n",
       "      <td>0.853784</td>\n",
       "      <td>0.889628</td>\n",
       "      <td>0.946290</td>\n",
       "      <td>3.152361e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970719</td>\n",
       "      <td>1127</td>\n",
       "      <td>1079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Liquid Staking</td>\n",
       "      <td>1123</td>\n",
       "      <td>(0, 1, 0)</td>\n",
       "      <td>(0, 1, 1, 7)</td>\n",
       "      <td>-3095.535220</td>\n",
       "      <td>1123</td>\n",
       "      <td>(0, 1, 0)</td>\n",
       "      <td>(0, 1, 1, 7)</td>\n",
       "      <td>-4236.966438</td>\n",
       "      <td>-0.292707</td>\n",
       "      <td>-0.368752</td>\n",
       "      <td>0.938120</td>\n",
       "      <td>0.939493</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1127</td>\n",
       "      <td>1123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Onchain Capital Allocator</td>\n",
       "      <td>344</td>\n",
       "      <td>(0, 1, 0)</td>\n",
       "      <td>(1, 1, 1, 7)</td>\n",
       "      <td>-353.864396</td>\n",
       "      <td>344</td>\n",
       "      <td>(1, 0, 2)</td>\n",
       "      <td>(1, 0, 0, 7)</td>\n",
       "      <td>-631.400960</td>\n",
       "      <td>0.407119</td>\n",
       "      <td>0.308340</td>\n",
       "      <td>0.825363</td>\n",
       "      <td>0.820494</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>0.965147</td>\n",
       "      <td>0.943700</td>\n",
       "      <td>360</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yield</td>\n",
       "      <td>1123</td>\n",
       "      <td>(1, 0, 1)</td>\n",
       "      <td>(0, 0, 0, 7)</td>\n",
       "      <td>-3194.468656</td>\n",
       "      <td>1123</td>\n",
       "      <td>(1, 0, 1)</td>\n",
       "      <td>(0, 0, 0, 7)</td>\n",
       "      <td>-2623.153299</td>\n",
       "      <td>0.610175</td>\n",
       "      <td>0.587684</td>\n",
       "      <td>0.391248</td>\n",
       "      <td>0.271688</td>\n",
       "      <td>3.518487e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1127</td>\n",
       "      <td>1123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    category  n_model_obs_TVR  order_TVR  seasonal_TVR  \\\n",
       "3                        CDP             1123  (2, 1, 1)  (0, 1, 1, 7)   \n",
       "4                       Dexs             1123  (2, 1, 1)  (0, 1, 1, 7)   \n",
       "1                    Lending             1079  (1, 1, 2)  (1, 1, 1, 7)   \n",
       "0             Liquid Staking             1123  (0, 1, 0)  (0, 1, 1, 7)   \n",
       "5  Onchain Capital Allocator              344  (0, 1, 0)  (1, 1, 1, 7)   \n",
       "2                      Yield             1123  (1, 0, 1)  (0, 0, 0, 7)   \n",
       "\n",
       "       AIC_TVR  n_model_obs_TVL  order_TVL  seasonal_TVL      AIC_TVL  \\\n",
       "3 -2438.011021             1123  (1, 0, 0)  (0, 0, 0, 7) -4838.770458   \n",
       "4 -2940.209362             1123  (2, 0, 1)  (0, 0, 0, 7) -2486.573752   \n",
       "1 -2891.671399             1079  (1, 1, 1)  (1, 1, 1, 7) -1394.945813   \n",
       "0 -3095.535220             1123  (0, 1, 0)  (0, 1, 1, 7) -4236.966438   \n",
       "5  -353.864396              344  (1, 0, 2)  (1, 0, 0, 7)  -631.400960   \n",
       "2 -3194.468656             1123  (1, 0, 1)  (0, 0, 0, 7) -2623.153299   \n",
       "\n",
       "   pearson_r_TVR  spearman_rho_TVR  pearson_r_TVL  spearman_rho_TVL  \\\n",
       "3      -0.663549         -0.555057      -0.415855         -0.344991   \n",
       "4       0.246724          0.265541       0.310997          0.282990   \n",
       "1       0.799375          0.853784       0.889628          0.946290   \n",
       "0      -0.292707         -0.368752       0.938120          0.939493   \n",
       "5       0.407119          0.308340       0.825363          0.820494   \n",
       "2       0.610175          0.587684       0.391248          0.271688   \n",
       "\n",
       "            thr  tvr_coverage  valid_coverage  N_tvr_pos  N_active  \n",
       "3  9.365115e+06      1.000000        1.000000       1127      1123  \n",
       "4  2.242641e+07      1.000000        1.000000       1127      1123  \n",
       "1  3.152361e+06      1.000000        0.970719       1127      1079  \n",
       "0  1.000000e+06      1.000000        1.000000       1127      1123  \n",
       "5  1.000000e+06      0.965147        0.943700        360       344  \n",
       "2  3.518487e+06      1.000000        1.000000       1127      1123  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 8. Export correlation summary table\n",
    "corr_df = pd.DataFrame(corr_rows).sort_values('category')\n",
    "out_path = os.path.join(OUTDIR if 'OUTDIR' in globals() else '.', 'correlation_summary.csv')\n",
    "corr_df.to_csv(out_path, index=False)\n",
    "print(f\"✓ The correlation coefficient has been exported: {out_path}\")\n",
    "display(corr_df)\n",
    "\n",
    "# 9.  summary_rows\n",
    "summary_df = pd.DataFrame(summary_rows).sort_values('category')\n",
    "sum_path = os.path.join(OUTDIR if 'OUTDIR' in globals() else '.', 'model_and_corr_summary.csv')\n",
    "summary_df.to_csv(sum_path, index=False)\n",
    "print(f\"✓ The model & correlation summary has been exported: {sum_path}\")\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef104140-7f69-4062-b77c-d06075d7e188",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
